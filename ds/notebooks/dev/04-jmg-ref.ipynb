{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Excellence Framework results from \n",
    "\n",
    "We read and convert the HEFCE Research Excellence Framework (REF) data which is available from HEFCE (weird link: https://results.ref.ac.uk/(S(hlvnuqzwkag44jp3df3d4q14))/)\n",
    "\n",
    "This is another university page with learning provider (`ukprn`) codes so the process that we will use to geocode the institutions is similar to what we did before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from nuts_finder import NutsFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_cols(my_csv):\n",
    "    '''\n",
    "    Tidies column names ie lower and replace spaces with underscores\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return([re.sub(' ','_',col.lower()) for col in my_csv.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NUTS aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nuts_estimate(data,nuts_lookup,counter,name):\n",
    "    '''\n",
    "    This function takes hesa data and creates a nuts estimate\n",
    "    \n",
    "    Args:\n",
    "        data (df) where we have already selected variables of interest eg mode of employment\n",
    "        nuts (dict) is the ukprn - nuts name and code lookup\n",
    "        counter (str) is the variable with counts that we are interested in\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    d = data.copy()\n",
    "    \n",
    "    #Add the nuts names and codes\n",
    "    d['nuts_name'],d['nuts_code'] = [[nuts_lookup[ukprn][var] if ukprn in nuts_lookup.keys() else np.nan for ukprn in data['ukprn']] for\n",
    "                                     var in ['nuts_name','nuts_code']]\n",
    "    \n",
    "    #We are focusing on numbers\n",
    "    d[counter] = d[counter].astype(float)\n",
    "    \n",
    "    out = d.groupby(['nuts_name','nuts_code'])[counter].sum()\n",
    "    \n",
    "    out.name = name\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_nuts_estimates(data,nuts_lookup,variables,select_var,value):\n",
    "    '''\n",
    "    Creates NUTS estimates for multiple variables.\n",
    "    \n",
    "    Args:\n",
    "        data (df) is the filtered dataframe\n",
    "        select_var (str) is the variable we want to use to select values\n",
    "        nuts_lookup (dict) is the lookup between universities and nuts\n",
    "        variables (list) is the list of variables for which we want to generate the analysis\n",
    "        value (str) is the field that contains the numerical value we want to aggregate in the dataframe\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    concat = pd.concat([make_nuts_estimate(data.loc[data[select_var]==m],nuts_lookup,value,m) for m in \n",
    "              variables],axis=1)\n",
    "    \n",
    "    return(concat)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hesa directory in raw and processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ref' not in os.listdir('../../data/raw'):\n",
    "    os.mkdir('../../data/raw/hef')\n",
    "    \n",
    "if 'ref' not in os.listdir('../../data/processed'):\n",
    "    os.mkdir('../../data/processed/ref')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read and evaluate the university NUTS dictionary\n",
    "with open('../../data/metadata/uni_nuts.txt','r') as infile:\n",
    "    uni_nuts = literal_eval(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEFCE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "ref = pd.read_excel('https://results.ref.ac.uk/(S(hlvnuqzwkag44jp3df3d4q14))/DownloadFile/AllResults/xlsx',skiprows=7,na_values='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.columns = tidy_cols(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_vars = ['institution_code_(ukprn)','institution_name','unit_of_assessment_name','profile','fte_category_a_staff_submitted','4*','3*','2*','1*','unclassified']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_2 = ref[focus_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing\n",
    "\n",
    "We want to do the following: \n",
    "\n",
    "* Estimate FTE in each category (multiply submitted by percentages)\n",
    "* Create NUTS aggregates\n",
    "* Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FTE in category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the full time estimate equivalents in each category\n",
    "\n",
    "for x in ['4*','3*','2*','1*','unclassified']:\n",
    "    \n",
    "    ref_2[x+'_fte'] = [fte*star/100 for fte,star in zip(ref_2['fte_category_a_staff_submitted'],ref_2[x])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on the overall variable rather than its components\n",
    "ref_3 = ref_2.loc[ref['profile']=='Overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we melt the ref df so it is easier to create the aggregations later.\n",
    "focus_vars_2 = ['institution_code_(ukprn)','institution_name','unit_of_assessment_name','4*_fte','3*_fte','2*_fte','1*_fte','unclassified_fte']\n",
    "\n",
    "\n",
    "ref_long = ref_3[focus_vars_2].melt(id_vars=['institution_code_(ukprn)','institution_name','unit_of_assessment_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We rename the variable with the ukprn code so it works with our functions\n",
    "ref_long.rename(columns={'institution_code_(ukprn)':'ukprn'},inplace=True)\n",
    "\n",
    "#We reduce the institute of zoology, which does not have a UKPRN\n",
    "\n",
    "ref_long = ref_long.loc[ref_long['ukprn']!='ZZZZZZZZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_long['ukprn'] = ref_long['ukprn'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to NUTS**\n",
    "\n",
    "We will subset by discicpline and aggregate over ftes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "#For each unique discipline\n",
    "for disc in set(ref_long['unit_of_assessment_name']):\n",
    "    \n",
    "    #Subset by that discipline\n",
    "    df_in_unit = ref_long.loc[ref_long['unit_of_assessment_name']==disc]\n",
    "    \n",
    "    #Aggregate over nuts\n",
    "    nuts_in_unit = multiple_nuts_estimates(df_in_unit,uni_nuts,set(df_in_unit['variable']),'variable','value')\n",
    "    \n",
    "    #Add the discipline (unit of assessment) name so we know what everything is when we concatenate\n",
    "    nuts_in_unit['unit_of_assessment_name'] = disc\n",
    "    \n",
    "    #Put in the list\n",
    "    out.append(nuts_in_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate\n",
    "nuts_ref_ftes = pd.concat(out,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tidy up variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FTE variables ordered\n",
    "fte_vars = ['4*_fte','3*_fte','2*_fte','1*_fte','unclassified_fte']\n",
    "\n",
    "nuts_ref_ftes = nuts_ref_ftes[['unit_of_assessment_name']+fte_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_ref_ftes['total_fte'] = nuts_ref_ftes[fte_vars].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini exploration\n",
    "\n",
    "high_score_discipline = nuts_ref_ftes.pivot_table(index='nuts_name',columns='unit_of_assessment_name',values='4*_fte').fillna(0)\n",
    "\n",
    "sn.clustermap(high_score_discipline.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above suggests that there is a 'classics' cluster with traditional disciplines, a more applied cluster, and a cluster of newer perhaps less academic disciplines. It would be very interesting to dig into this much deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_ref_ftes.to_csv(f'../../data/processed/ref/{today_str}_ref_nuts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
