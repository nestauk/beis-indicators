{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Official data indicators\n",
    "\n",
    "Here we collect data and create indicators of industrial activity in NUTS2 areas based on BRES and NOMIS data.\n",
    "\n",
    "<!-- We have already collected the data by running `make data` in the terminal. This has stored the BRES and IDBR data in the `data/external/` folder, and processed it into Nesta segments (a shorter number of industrial categories) in `data/processed`\n",
    " -->\n",
    " \n",
    "This involves running the script `make_dataset.py`. This already results in indicators that are relevant for the project, such as complexity. \n",
    " \n",
    "We will also create a clean table and an indicator of the share of employment working in high median salary occupations according to the ashe data we calculate in `0-jmg-ashe_sectoral`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to put this in utils\n",
    "def make_dirs(name,dirs = ['raw','processed','interim']):\n",
    "    '''\n",
    "    Utility that creates directories to save the data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for d in dirs:\n",
    "        if name not in os.listdir(f'../../data/{d}'):\n",
    "            os.mkdir(f'../../data/{d}/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_industry_dataset(path,salary_lookup,cluster_name,year,save=False):\n",
    "    '''\n",
    "    This creates a long dataset with industry activity per NUTS area and extra variables with share of activity in top two deciles\n",
    "    of salary, and bottom two deciles of salary\n",
    "    \n",
    "    Arguments:\n",
    "        path (str) path to a tidy dataframe with the industrial activity information (could be employment or establishments)\n",
    "        salary_lookup (dict) a lookup between industry segments and position in the salary distribution\n",
    "        cluster_name (str) name of the cluster variable in the industry df\n",
    "    \n",
    "    '''\n",
    "    #Read the data\n",
    "    industry = pd.read_csv(path,dtype={'SIC4':str})\n",
    "    \n",
    "    #Label with salary info\n",
    "    industry['median_salary_decile'] = industry[cluster_name].map(ashe_lookup)\n",
    "    \n",
    "    #Create wide dataset with industry activity per geography\n",
    "    industry_long = industry.groupby(\n",
    "        ['geo_nm','geo_cd',cluster_name])['value'].sum().reset_index(drop=False).pivot_table(\n",
    "        index=['geo_nm','geo_cd'],columns=cluster_name,values='value')\n",
    "    \n",
    "    #Share of activity in top and bottom of salary distribution\n",
    "    salary_long = industry.groupby(\n",
    "        ['geo_nm','geo_cd','median_salary_decile'])['value'].sum().reset_index(drop=False).pivot_table(\n",
    "        index=['geo_nm','geo_cd'],columns='median_salary_decile',values='value')\n",
    "    \n",
    "    #Top of distro\n",
    "    high_salary = salary_long.apply(lambda x: x/x.sum(),axis=1)[[8,9]].sum(axis=1)\n",
    "    \n",
    "    #Bottom of distro\n",
    "    low_salary = salary_long.apply(lambda x: x/x.sum(),axis=1)[[0,1]].sum(axis=1)\n",
    "    \n",
    "    salary_stats = pd.concat([high_salary,low_salary],axis=1)\n",
    "    \n",
    "    #Names\n",
    "    salary_stats.columns = ['top_20_salary_share','bottom_20_salary_share']\n",
    "    \n",
    "    #Concatenate\n",
    "    combined = pd.concat([industry_long,salary_stats],axis=1)\n",
    "    \n",
    "    if save==True:\n",
    "        \n",
    "        #Take the informative bit of the name\n",
    "        name = '_'.join(path.split('_')[1:3])\n",
    "        \n",
    "        combined.to_csv(f'../../data/interim/industry/{today_str}_{name}_industry_salary.csv')\n",
    "        \n",
    "    \n",
    "    salary_stats['year']=year\n",
    "    return(salary_stats)\n",
    "    \n",
    "    #Return everything\n",
    "    \n",
    "    \n",
    "    #return(salary_long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segment(path,sector_list,sector_variable,sector_name):\n",
    "    '''\n",
    "    This function takes official data from a path and returns a segment of interest.\n",
    "    We will use it to produce indicators about cultural activities in different NUTS2 regions.\n",
    "    \n",
    "    Arguments:\n",
    "        path (str) is the path we use\n",
    "        segment (list) is the list of codes we are interested in - could be segments or sectors\n",
    "        sector_variable (str) is the variable that we use to identify sectors. It could be \n",
    "            the sic code or the Nesta segment.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Read data\n",
    "    all_sectors = pd.read_csv(path,dtype={'SIC4':str})\n",
    "    \n",
    "    #Activity in sector\n",
    "    sector = all_sectors.loc[[x in sector_list for x in all_sectors[sector_variable]]].reset_index(\n",
    "        drop=True)\n",
    "    \n",
    "    #Regroup and aggregate\n",
    "    sector_agg = sector.groupby(['geo_nm','geo_cd','year'])['value'].sum()\n",
    "    \n",
    "    #Add the name\n",
    "    sector_agg.name = sector_name\n",
    "    \n",
    "    #Create dataframe so we can add years\n",
    "    #sector_agg = pd.DataFrame(sector_agg)\n",
    "    \n",
    "    #And add years\n",
    "    #sector_agg['year'] = year\n",
    "    \n",
    "    return(pd.DataFrame(sector_agg))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_indicator(table,target_path,var_lookup,year_var,nuts_var='nuts_code',nuts_spec=2018,decimals=3):\n",
    "    '''\n",
    "    We use this function to create and save indicators using our standardised format.\n",
    "    \n",
    "    Args:\n",
    "        table (df) is a df with relevant information\n",
    "        target_path (str) is the location of the directory where we want to save the data (includes interim and processed)\n",
    "        var_lookup (dict) is a lookup to rename the variable into our standardised name\n",
    "        year (str) is the name of the year variable\n",
    "        nuts_var (str) is the name of the NUTS code variable. We assume it is nuts_code\n",
    "        nuts_spec (y) is the value of the NUTS specification. We assume we are working with 2018 NUTS\n",
    "    \n",
    "    '''\n",
    "    #Copy\n",
    "    t = table.reset_index(drop=False)\n",
    "    \n",
    "    #Reset index (we assume that the index is the nuts code, var name and year - this might need to be changed)\n",
    "    \n",
    "    \n",
    "    #Process the interim data into an indicator\n",
    "    \n",
    "    #This is the variable name and code\n",
    "    var_name = list(var_lookup.keys())[0]\n",
    "    \n",
    "    var_code = list(var_lookup.values())[0]\n",
    "    \n",
    "    #Focus on those\n",
    "    t = t[[year_var,nuts_var,var_name]]\n",
    "    \n",
    "    #Add the nuts specification\n",
    "    t['nuts_year_spec'] = nuts_spec\n",
    "    \n",
    "    #Rename variables\n",
    "    t.rename(columns={var_name:var_code,year_var:'year',nuts_var:'region_id'},inplace=True)\n",
    "\n",
    "    #Round variables\n",
    "    t[var_code] = [np.round(x,decimals) if decimals>0 else int(x) for x in t[var_code]]\n",
    "    \n",
    "    \n",
    "    #Reorder variables\n",
    "    t = t[['year','region_id','nuts_year_spec',var_code]]\n",
    "    \n",
    "    print(t.head())\n",
    "    \n",
    "    #Save in the processed folder\n",
    "    t.to_csv(f'../../data/processed/{target_path}/{var_code}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dirs('industry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cultural industries \n",
    "\n",
    "cultural = ['services_cultural','services_recreation','services_entertainment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata (ASHE)\n",
    "\n",
    "This is a lookup indicating the position in the salary distribution of various industries based on the analysis in the `ashe` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read ashe and turn it into a lookup\n",
    "ashe = pd.read_csv('../../data/interim/industry/2020_02_18_ashe_rankings.csv')\n",
    "\n",
    "ashe_lookup = ashe.set_index('cluster')['ashe_median_salary_rank'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bres\n",
    "bres_2018 = pd.read_csv('../../data/interim/industry/nomis_BRES_2018_TYPE450.csv',dtype={'SIC4':str},\n",
    "                       index_col=None)\n",
    "\n",
    "bres_2018['sal'] = bres_2018['cluster_name'].map(ashe_lookup)\n",
    "\n",
    "bres_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level of employment in the cultural industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bres_cult = pd.concat([extract_segment(\n",
    "    f'../../data/interim/industry/nomis_BRES_{y}_TYPE450.csv',cultural,'cluster_name',\n",
    "    'culture_entertainment_recreation') for y in [2016,2017,2018]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_indicator(bres_cult,\n",
    "               'industry',\n",
    "               {'culture_entertainment_recreation':'employment_culture_entertainment_recreation'},year_var='year',\n",
    "              nuts_spec=2013,nuts_var='geo_cd',decimals=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level of employment and business activity in sectors with different salaries\n",
    "\n",
    "We are not saving these for now as they are not key to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bres_nuts,idbr_nuts = [pd.concat([create_local_industry_dataset(\n",
    "    f'../../data/interim/industry/nomis_{data}_{y}_TYPE450.csv',ashe_lookup,'cluster_name',y) \n",
    "                       for y in [2016,2017,2018]]) for data in ['BRES','IDBR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compl= pd.read_csv('../../data/interim/industry/nomis_ECI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_indicator(compl.loc[compl['source']=='BRES'],\n",
    "#               'industry',\n",
    "#               {'eci':'economic_complexity_index'},year_var='year',nuts_spec=2013,nuts_var='geo_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
