{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trademarks\n",
    "\n",
    "Here we collect open trademark data from the Intellectual Property Office. \n",
    "\n",
    "The data is available here: https://www.gov.uk/government/publications/ipo-trade-mark-data-release\n",
    "\n",
    "We will undertake the following activities:\n",
    "\n",
    "* Collect all the data.\n",
    "* Enrich it with information about the product codes that the trademarks refer to\n",
    "* Enrich it with information about its NUTS location (we keep this flexible as we will using this code in multiple places)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirs\n",
    "\n",
    "if 'trademarks' not in os.listdir('../../data/raw'):\n",
    "    os.makedirs('../../data/raw/trademarks')\n",
    "\n",
    "if 'trademarks' not in os.listdir('../../data/processed/'):\n",
    "    os.makedirs('../../data/processed/trademarks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../utilities.py\n",
    "# Some utilities\n",
    "\n",
    "import random\n",
    "\n",
    "def make_data_dict(table,name,path,sample=5):\n",
    "    '''\n",
    "    A function to output the form for a data dictionary\n",
    "    \n",
    "    Args:\n",
    "        -table (df) is the df we want to create the data dictionary for\n",
    "        -name (str) of the df\n",
    "        -path (str) is the place where we want to save the file\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    types = [estimate_type(table[x],sample=sample) for x in table.columns]\n",
    "        \n",
    "    data_dict = pd.DataFrame()\n",
    "    data_dict['variable'] = table.columns\n",
    "        \n",
    "    data_dict['type'] = types\n",
    "    \n",
    "    data_dict['description'] = ['' for x in data_dict['variable']]\n",
    "        \n",
    "    out = os.path.join(path,f'{today_str}_{name}.csv')\n",
    "    \n",
    "    #print(data_dict.columns)\n",
    "    \n",
    "    data_dict.to_csv(out)\n",
    "    \n",
    "\n",
    "def estimate_type(variable,sample):\n",
    "    '''\n",
    "    Estimates the type of a column. \n",
    "\n",
    "    Args:\n",
    "        variable (iterable) with values\n",
    "        sample (n) is the number of values to test\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    selection = random.sample(list(variable),sample)\n",
    "    \n",
    "    types = pd.Series([type(x) for x in selection]).value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    return(types.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data\n",
    "\n",
    "We collect the data from the IPOs open data site. This is a zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect trademark open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and parse the data\n",
    "trademark_link = 'https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/680986/opendatadomestic.zip'\n",
    "trade_request = requests.get(trademark_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradem = ZipFile(BytesIO(trade_request.content)).extract('OpenDataDomestic.txt',path=f'../../data/raw/trademarks/{today_str}_trademarks.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that here we are escaping a small number (~20) of badlines.\n",
    "#I couldn't quite determine what was the problem with them\n",
    "\n",
    "tradem_df = pd.read_csv('../../data/raw/trademarks/12_11_2019_trademarks.txt/OpenDataDomestic.txt',delimiter='|',\n",
    "                        encoding='utf-16',warn_bad_lines=False,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what it looks like\n",
    "tradem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tidy the columns\n",
    "tradem_df.columns = [re.sub(' ','_',x).lower() for x in tradem_df.columns]\n",
    "\n",
    "#Convert year strings to years. Faster with string processing than with datetime\n",
    "tradem_df['year_published'] = [int(str(x).split('-')[0]) if not pd.isnull(x) else x for x in tradem_df.published]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product - category lookup\n",
    "\n",
    "We will use this lookup to identify patents with scientific Nice codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_product_category_lookup = pd.read_csv('../../data/aux/12_11_2019_nice_class_to_category_lookup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geocoding the trademarks\n",
    "\n",
    "We are going to create a function that automatically geocodes the trademarks using a postcode-NUTS lookup. One challenge with this is that both postcodes and NUTS classifications change over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean postcodes\n",
    "tradem_df['postcode'] = [x.strip().lower() if (pd.isnull(x)==False) & (x!='Not Available') else np.nan for x in tradem_df.postcode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradem_uk = tradem_df.loc[tradem_df['country']=='United Kingdom'].dropna(axis=0,subset=['postcode'])\n",
    "\n",
    "len(tradem_uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the trademarks in the UK with postcodes. We can use them in subsequent analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_url = 'https://www.arcgis.com/sharing/rest/content/items/19fac93960554b5e90840505bd73917f/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_trademark(tradem_df,geography,nspl_file,lookup_file,geo_code,path_to_nspl):\n",
    "    '''\n",
    "    \n",
    "    This function classifies trademars into locations using a postcode Lookup. As part of this we need to merge the merged file with a geo-code - geo-name\n",
    "    lookup to get the geography names.\n",
    "    \n",
    "    Arguments:\n",
    "        tradem_df (df) is the df with the trademark information. It needs to include a postode for matching\n",
    "        geography (str) is the geography we want to match\n",
    "        nspl_file (str) is the file with the nspl data\n",
    "        lookup_file (str) is the name of the file with a lookup between variable names and codes\n",
    "        geo_code (str) is the name of the variable name in the lookup\n",
    "        path_to_nspl (str) if a link, then we download the nspl file.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Read the NSPL files\n",
    "    \n",
    "    if 'https' in path_to_nspl:\n",
    "        \n",
    "        print('downloading nspl')\n",
    "        \n",
    "        #Download the file\n",
    "        nspl_request = requests.get(path_to_nspl)\n",
    "        \n",
    "        nspl_zipfile = ZipFile(BytesIO(nspl_request.content))\n",
    "        \n",
    "        #Read the nspl\n",
    "        nspl = pd.read_csv(nspl_zipfile.open(f'Data/{nspl_file}'))[['pcds',geography]]\n",
    "        \n",
    "        #Read the lookup\n",
    "        lookup = pd.read_csv(nspl_zipfile.open(f'Documents/{lookup_file}'))\n",
    "        \n",
    "    else:\n",
    "        print('reading nspl')\n",
    "        \n",
    "        nspl = pd.read_csv(path_to_nspl+f'/Data/{nspl_file}')[['pcds',geography]]\n",
    "        \n",
    "        lookup = pd.read_csv(path_to_nspl+f'/Documents/{lookup_file}')\n",
    "        \n",
    "       \n",
    "    print('processing data')\n",
    "    #Throw away unnecessary postcodes in the nspl file (we are only interested in the first digit. Also, make them lowercase\n",
    "    nspl['pcds_1st'] = nspl['pcds'].apply(lambda x: x.split(' ')[0].lower())\n",
    "    \n",
    "    \n",
    "    #Merge\n",
    "    tradem_merged = pd.merge(tradem_df,nspl.drop_duplicates('pcds_1st')[['pcds_1st',geography]],left_on='postcode',right_on='pcds_1st')\n",
    "    \n",
    "    \n",
    "    #Merge with the lookup names\n",
    "    #Remove Walsh column names from lookup\n",
    "    lookup = lookup[[x for x in lookup.columns if x[-1]!='W']]\n",
    "    \n",
    "    tradem_w_names = pd.merge(tradem_merged,lookup,left_on=geography,right_on=geo_code)\n",
    "    \n",
    "    #Remove the geography variable as it has unstandardised names\n",
    "    tradem_w_names.drop(axis=1,labels=geography,inplace=True)\n",
    "    \n",
    "    return(tradem_w_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_nuts = geo_trademark(tradem_df,geography='nuts',nspl_file='NSPL_AUG_2019_UK.csv',\n",
    "                            lookup_file='LAU219_LAU119_NUTS18_MAY_2019_UK_LU.csv',\n",
    "                            geo_code='LAU219CD',path_to_nspl = pc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_nuts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing\n",
    "\n",
    "We will create a df with registered trademark counts after 2010, and counts of trademarks in scientific and technnological nice codes. \n",
    "\n",
    "We identify what these are using the lookup we created in our project mapping innovation in Scotland, and which we loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to focus on recent & registered trademarks\n",
    "trademark_clean = trademark_nuts.loc[(trademark_nuts['status']=='Registered')&(trademark_nuts['year_published']>=2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the scientic classes?\n",
    "class_product_category_lookup.loc[class_product_category_lookup['category']=='scientific']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientic_nice_classes = list(class_product_category_lookup.loc[class_product_category_lookup['category']=='scientific']['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does a trademark have at least one scientific category?\n",
    "#trademark_clean['is_scientific'] = trademark_nuts[scientic_nice_classes].sum(axis=1)>0\n",
    "\n",
    "trademark_clean['is_scientific'] = trademark_nuts['class42']>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_clean['is_scientific'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by NUTS to create aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_grouped = pd.concat([trademark_clean.groupby(['NUTS218NM','NUTS218CD']).size(),\n",
    "                            trademark_clean.groupby(['NUTS218NM','NUTS218CD'])['is_scientific'].sum()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_grouped.rename(columns={0:'trademark_n','is_scientific':'scientific_trademark_n'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_grouped['scientific_trademark_share'] = trademark_grouped['scientific_trademark_n']/trademark_grouped['trademark_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_grouped.sort_values('scientific_trademark_share',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademark_grouped.to_csv(f'../../data/processed/trademarks/{today_str}_nuts_trademarks.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
