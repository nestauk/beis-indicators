{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gateway to Research\n",
    "\n",
    "This repo processes and produces indicators based on the Gateway to Research data.\n",
    "\n",
    "See [here](https://github.com/nestauk/gtr_data_processing) for a fuller description of data processing and enrichment.\n",
    "\n",
    "We will use a dataset with information about projects to create the following indicators:\n",
    "\n",
    "* Level of activity in and funding received by discipline (focusing on projects led by organisations in a location)\n",
    "* Number of participations in research (to capture research participation by organisations that aren't in NUTS with lots of universities)\n",
    "* Dyadic collaborations (instances where projects include pairs of organisations from the same location)\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "In this version of the notebook we are using `data_getters_lab` to get a processed version of the gtr data from Nesta DAPS. In a future version we will make the raw data available in a AWS bucket or something along the lines that non-Nesta researchers can use to access the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import random\n",
    "from beis_indicators.utils.nuts_utils import auto_nuts2_uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions etc down here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(name,dirs = ['raw','processed']):\n",
    "    '''\n",
    "    Utility that creates directories to save the data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for d in dirs:\n",
    "        if name not in os.listdir(f'../../data/{d}'):\n",
    "            os.mkdir(f'../../data/{d}/{name}')\n",
    "            \n",
    "def flat_freq(a_list):\n",
    "    '''\n",
    "    Return value counts for categories in a nested list\n",
    "    \n",
    "    '''\n",
    "    return(pd.Series([x for el in a_list for x in el]).value_counts())\n",
    "\n",
    "        \n",
    "\n",
    "def flatten_list(a_list):\n",
    "    \n",
    "    return([x for el in a_list for x in el])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gtr_data(df,vars_to_parse):\n",
    "    '''\n",
    "    \n",
    "    This function parses strings into lists\n",
    "    \n",
    "    Args:\n",
    "        df is the df whose columns we want to parsr\n",
    "        vars_to_parse is a list with the variables to parse\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #If the column is in the list above, then parse it\n",
    "    for c in df.columns:\n",
    "    \n",
    "        if c in vars_to_parse:\n",
    "            df[c] = [literal_eval(x) for x in df[c]]\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hopefully this will allow us to convert into the new variables\n",
    "\n",
    "def convert_to_nut(list_of_lads,lookup,value):\n",
    "    '''\n",
    "    This function converts a list where every element is a lad code into a list where every element is a nuts code (or name!)\n",
    "    \n",
    "    Arguments:\n",
    "        list_of_lads (iterable) is an iterable where every element is a list of LAD codes.\n",
    "        lookups (dict) is a lookup between lad codes and NUT 2 codes and names\n",
    "        value (str) is whether we want to output NUT codes or names\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Note that we have some control flow to deal with LADS missing from the lookup (it might happen) \n",
    "    out = [[lookup[x][value] if x in lookup.keys() else np.nan for x in el] for el in list_of_lads]\n",
    "    \n",
    "    return(out)\n",
    "\n",
    "def convert_to_nut_multiple(df,var):\n",
    "    '''\n",
    "    \n",
    "    This function automates some of the above eg. we can choose one variable suffix (lead, all) and it automatically converts to nuts names and lads\n",
    "    \n",
    "    Note - this directly transforms the input df\n",
    "    \n",
    "    Arguments:\n",
    "        df (df) is the dataframe where we want to add the converted variables\n",
    "        var (str) is the list of lad codes that we want to convert to nuts codes and names\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    df[f'{var}_nut_code'],df[f'{var}_nut_name'] = [convert_to_nut(df[f'{var}_lad_code'],lads_to_nuts_lookup,n) for n in nut_vars]\n",
    "    \n",
    "    #return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_geo_var_stats(df,geo='nut',var='disc_top_discipline'):\n",
    "    '''\n",
    "    This function takes a df with project activity and creates discipline project counts and total amounts by geography\n",
    "    \n",
    "    Arguments:\n",
    "        df (df) is a dataframe where one of the columns is the geography and another the top discipline (or funder - we could change this)\n",
    "        geo (str) is the variable we want to use in the geo analysis\n",
    "        var (str) is the variable we want to get project counts and amounts of funding for\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df_2 = df.copy()\n",
    "\n",
    "    \n",
    "    #Extract variable names and codes from list\n",
    "    df_2[f'lead_{geo}_name'],df_2[f'lead_{geo}_code']= [[x[0] if len(x)>0 else np.nan for x in df_2[var]] for var in [f'lead_{geo}_name',\n",
    "                                                                                        f'lead_{geo}_code']]\n",
    "    \n",
    "    \n",
    "    #Project frequencies by variable and geography\n",
    "    project_geo_counts = df_2.groupby([f'lead_{geo}_name',f'lead_{geo}_code','year'])[var].value_counts()\n",
    "\n",
    "    project_geo_counts.name = 'project_count'\n",
    "\n",
    "    #Pivot to create a wide version\n",
    "\n",
    "    project_wide = project_geo_counts.reset_index(drop=False).pivot_table(index=[f'lead_{geo}_name',f'lead_{geo}_code','year'],\n",
    "                                                                columns=var,values='project_count',aggfunc='sum').fillna(0)\n",
    "\n",
    "    project_wide.columns = [x+'_project_n' for x in project_wide]\n",
    "    \n",
    "    #Project funding by discipline\n",
    "    project_geo_funding = df_2.groupby([f'lead_{geo}_name',f'lead_{geo}_code',var,'year'])['amount'].sum()\n",
    "\n",
    "    fund_wide = project_geo_funding.reset_index(drop=False).pivot_table(index=[f'lead_{geo}_name',f'lead_{geo}_code','year'],\n",
    "                                                                columns=var,values='amount',aggfunc='sum').fillna(0)\n",
    "\n",
    "    fund_wide.columns = [x+'_funding_gpb' for x in fund_wide]\n",
    "    \n",
    "    out = pd.concat([project_wide,fund_wide],axis=1)\n",
    "    \n",
    "    return(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../utilities.py\n",
    "# Some utilities\n",
    "\n",
    "def make_data_dict(table,name,path,sample=5):\n",
    "    '''\n",
    "    A function to output the form for a data dictionary\n",
    "    \n",
    "    Args:\n",
    "        -table (df) is the df we want to create the data dictionary for\n",
    "        -name (str) of the df\n",
    "        -path (str) is the place where we want to save the file\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    types = [estimate_type(table[x],sample=sample) for x in table.columns]\n",
    "        \n",
    "    data_dict = pd.DataFrame()\n",
    "    data_dict['variable'] = table.columns\n",
    "        \n",
    "    data_dict['type'] = types\n",
    "    \n",
    "    data_dict['description'] = ['' for x in data_dict['variable']]\n",
    "        \n",
    "    out = os.path.join(path,f'{today_str}_{name}.csv')\n",
    "    \n",
    "    #print(data_dict.columns)\n",
    "    \n",
    "    data_dict.to_csv(out)\n",
    "    \n",
    "\n",
    "def estimate_type(variable,sample):\n",
    "    '''\n",
    "    Estimates the type of a column. \n",
    "\n",
    "    Args:\n",
    "        variable (iterable) with values\n",
    "        sample (n) is the number of values to test\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    selection = random.sample(list(variable),sample)\n",
    "    \n",
    "    types = pd.Series([type(x) for x in selection]).value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    return(types.index[0])\n",
    "\n",
    "                           \n",
    "                           \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_indicator(table,target_path,var_lookup,year_var,nuts_var='nuts_code',nuts_spec=2018,decimals=3):\n",
    "    '''\n",
    "    We use this function to create and save indicators using our standardised format.\n",
    "    \n",
    "    Args:\n",
    "        table (df) is a df with relevant information\n",
    "        target_path (str) is the location of the directory where we want to save the data (includes interim and processed)\n",
    "        var_lookup (dict) is a lookup to rename the variable into our standardised name\n",
    "        year (str) is the name of the year variable\n",
    "        nuts_var (str) is the name of the NUTS code variable. We assume it is nuts_code\n",
    "        nuts_spec (y) is the value of the NUTS specification. We assume we are working with 2018 NUTS\n",
    "    \n",
    "    '''\n",
    "    #Copy\n",
    "    t = table.reset_index(drop=False)\n",
    "    \n",
    "    #Reset index (we assume that the index is the nuts code, var name and year - this might need to be changed)\n",
    "    \n",
    "    \n",
    "    #Process the interim data into an indicator\n",
    "    \n",
    "    #This is the variable name and code\n",
    "    var_name = list(var_lookup.keys())[0]\n",
    "    \n",
    "    var_code = list(var_lookup.values())[0]\n",
    "    \n",
    "    #Focus on those\n",
    "    t = t[[year_var,nuts_var,var_name]]\n",
    "    \n",
    "    #Add the nuts specification\n",
    "    t['nuts_year_spec'] = nuts_spec\n",
    "    \n",
    "    #Rename variables\n",
    "    t.rename(columns={var_name:var_code,year_var:'year',nuts_var:'nuts_id'},inplace=True)\n",
    "\n",
    "    #Round variables\n",
    "    t[var_code] = [np.round(x,decimals) if decimals>0 else int(x) for x in t[var_code]]\n",
    "    \n",
    "    \n",
    "    #Reorder variables\n",
    "    t = t[['year','nuts_id','nuts_year_spec',var_code]]\n",
    "    \n",
    "    print(t.head())\n",
    "    \n",
    "    #Save in the processed folder\n",
    "    t.to_csv(f'../../data/processed/{target_path}/{var_code}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differently from other sources, we put the data in external because it has already been pre-processed\n",
    "make_dirs('gtr',['processed','interim','raw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_df = pd.read_csv('http://geoportal1-ons.opendata.arcgis.com/datasets/9b4c94e915c844adb11e15a4b1e1294d_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a lookup between LADS and NUTS codes and names\n",
    "lads_to_nuts_lookup = {\n",
    "    rid: {'NUTS218CD':row['NUTS218CD'],'NUTS218NM':row['NUTS218NM']} for rid,row in nuts_df.set_index('LAD18CD')[['NUTS218CD','NUTS218NM']].iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also a nuts code to name lookup\n",
    "nuts_code_to_name = {x['NUTS218CD']:x['NUTS218NM'] for rid,x in nuts_df.drop_duplicates('NUTS218CD').iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data\n",
    "\n",
    "From Nesta data getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_getters.labs.core import download_file\n",
    "\n",
    "\n",
    "def get_gtr(file,file_path,progress=True):\n",
    "    \"\"\" Fetch Gateway To Research predicted industries\n",
    "\n",
    "    Repo: https://github.com/nestauk/gtr_data_processing\n",
    "    Commit: cd3cddb\n",
    "    File: https://github.com/nestauk/gtr_data_processing/blob/master/notebooks/05_jmg_data_demo.ipynb\n",
    "\n",
    "    Args:\n",
    "        file_path (`str`, optional): Path to download to. If None, stream file.\n",
    "        progress (`bool`, optional): If `True` and `file_path` is not `None`,\n",
    "            display download progress.\n",
    "    \"\"\"\n",
    "    \n",
    "    return download_file(file_to_fetch=file, download_path=file_path+file, progress=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the data and save in the folders we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-21 08:28:39,138 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "gtr_org = get_gtr(file='17_9_2019_gtr_orgs.csv',file_path='../../data/raw/gtr/',progress=False)\n",
    "\n",
    "gtr_proj = get_gtr(file='17_9_2019_gtr_projects.csv',file_path='../../data/raw/gtr/',progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "gtr_proj = pd.read_csv('../../data/raw/gtr/17_9_2019_gtr_projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some tidying up\n",
    "\n",
    "#Remove the unnamed columns\n",
    "gtr_proj = gtr_proj[[x for x in gtr_proj.columns if 'Unnamed' not in x]]\n",
    "\n",
    "#Parse lists\n",
    "list_var = [x for x in gtr_proj.columns if '_lad_' in x]\n",
    "\n",
    "gtr_proj = parse_gtr_data(gtr_proj,list_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are not interested in columns between 24 and 102, which includes modelled industry and SDG variables\n",
    "\n",
    "gtr_proj = gtr_proj.iloc[:,[n for n in np.arange(0,len(gtr_proj.columns)) if n not in set(np.arange(25,103))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geoprocessing\n",
    "\n",
    "In previous work we geocoded the GtR data with LADS. Now we want to transfer this to NUTS2, the geographical unit of analysis for this project.\n",
    "\n",
    "Let's do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the functions defined above to convert lads to nuts\n",
    "nut_vars = ['NUTS218CD','NUTS218NM']\n",
    "\n",
    "\n",
    "convert_to_nut_multiple(gtr_proj,'lead')\n",
    "convert_to_nut_multiple(gtr_proj,'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>funder</th>\n",
       "      <th>status</th>\n",
       "      <th>grant_category</th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>...</th>\n",
       "      <th>involved_lad_code</th>\n",
       "      <th>involved_lad_name</th>\n",
       "      <th>lead_scot</th>\n",
       "      <th>inv_scot</th>\n",
       "      <th>inv_scot_n</th>\n",
       "      <th>short_abstract</th>\n",
       "      <th>lead_nut_code</th>\n",
       "      <th>lead_nut_name</th>\n",
       "      <th>all_nut_code</th>\n",
       "      <th>all_nut_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9BCF2DEE-0911-4D95-9259-84AEC7D51AC6</td>\n",
       "      <td>Wars of Position: Communism and Civil Society</td>\n",
       "      <td>Coinciding with the centenary of the October r...</td>\n",
       "      <td>2016</td>\n",
       "      <td>AHRC</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Fellowship</td>\n",
       "      <td>143026</td>\n",
       "      <td>GBP</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[UKD3]</td>\n",
       "      <td>[Greater Manchester]</td>\n",
       "      <td>[UKD3]</td>\n",
       "      <td>[Greater Manchester]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52405730-6906-4BDD-B9FC-FEB8E6C97E84</td>\n",
       "      <td>Burning fat: an in vivo and in vitro study of ...</td>\n",
       "      <td>People in the UK are getting fatter and this h...</td>\n",
       "      <td>2012</td>\n",
       "      <td>BBSRC</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>363926</td>\n",
       "      <td>GBP</td>\n",
       "      <td>...</td>\n",
       "      <td>[E07000242, E07000041, E06000030, E07000178, E...</td>\n",
       "      <td>[East Hertfordshire, Exeter, Swindon, Oxford, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[UKH1]</td>\n",
       "      <td>[East Anglia]</td>\n",
       "      <td>[UKH1, UKH2, UKK4, UKK1, UKJ1, UKJ1]</td>\n",
       "      <td>[East Anglia, Bedfordshire and Hertfordshire, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CBA76D0D-2D95-4028-B8DE-65041D8D1F85</td>\n",
       "      <td>Atomic-Scale Characterisation of Reactor Press...</td>\n",
       "      <td>The reactor pressure vessel (RPV) is a safety ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPSRC</td>\n",
       "      <td>Active</td>\n",
       "      <td>Studentship</td>\n",
       "      <td>0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[UKJ1]</td>\n",
       "      <td>[Berkshire, Buckinghamshire and Oxfordshire]</td>\n",
       "      <td>[UKJ1]</td>\n",
       "      <td>[Berkshire, Buckinghamshire and Oxfordshire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>82E47A5E-A4C6-4F70-9242-821EFC9456D7</td>\n",
       "      <td>University of the West of Scotland Nuclear Phy...</td>\n",
       "      <td>It is just over 100 years since Ernest Rutherf...</td>\n",
       "      <td>2014</td>\n",
       "      <td>STFC</td>\n",
       "      <td>Active</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>379758</td>\n",
       "      <td>GBP</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[UKM8]</td>\n",
       "      <td>[West Central Scotland]</td>\n",
       "      <td>[UKM8]</td>\n",
       "      <td>[West Central Scotland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>05BE79C5-AF13-4A67-B042-3BCE38D575A2</td>\n",
       "      <td>Transcription factor hierarchies underlying th...</td>\n",
       "      <td>Our sense of hearing, and the information we u...</td>\n",
       "      <td>2017</td>\n",
       "      <td>BBSRC</td>\n",
       "      <td>Active</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>351052</td>\n",
       "      <td>GBP</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[UKH1]</td>\n",
       "      <td>[East Anglia]</td>\n",
       "      <td>[UKH1]</td>\n",
       "      <td>[East Anglia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                            project_id  \\\n",
       "0      0  9BCF2DEE-0911-4D95-9259-84AEC7D51AC6   \n",
       "1      2  52405730-6906-4BDD-B9FC-FEB8E6C97E84   \n",
       "2      3  CBA76D0D-2D95-4028-B8DE-65041D8D1F85   \n",
       "3      4  82E47A5E-A4C6-4F70-9242-821EFC9456D7   \n",
       "4      6  05BE79C5-AF13-4A67-B042-3BCE38D575A2   \n",
       "\n",
       "                                               title  \\\n",
       "0      Wars of Position: Communism and Civil Society   \n",
       "1  Burning fat: an in vivo and in vitro study of ...   \n",
       "2  Atomic-Scale Characterisation of Reactor Press...   \n",
       "3  University of the West of Scotland Nuclear Phy...   \n",
       "4  Transcription factor hierarchies underlying th...   \n",
       "\n",
       "                                            abstract  year funder  status  \\\n",
       "0  Coinciding with the centenary of the October r...  2016   AHRC  Closed   \n",
       "1  People in the UK are getting fatter and this h...  2012  BBSRC  Closed   \n",
       "2  The reactor pressure vessel (RPV) is a safety ...  2018  EPSRC  Active   \n",
       "3  It is just over 100 years since Ernest Rutherf...  2014   STFC  Active   \n",
       "4  Our sense of hearing, and the information we u...  2017  BBSRC  Active   \n",
       "\n",
       "   grant_category  amount currency  ...  \\\n",
       "0      Fellowship  143026      GBP  ...   \n",
       "1  Research Grant  363926      GBP  ...   \n",
       "2     Studentship       0      GBP  ...   \n",
       "3  Research Grant  379758      GBP  ...   \n",
       "4  Research Grant  351052      GBP  ...   \n",
       "\n",
       "                                   involved_lad_code  \\\n",
       "0                                                 []   \n",
       "1  [E07000242, E07000041, E06000030, E07000178, E...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                   involved_lad_name  lead_scot  inv_scot  \\\n",
       "0                                                 []      False     False   \n",
       "1  [East Hertfordshire, Exeter, Swindon, Oxford, ...      False     False   \n",
       "2                                                 []      False     False   \n",
       "3                                                 []       True     False   \n",
       "4                                                 []      False     False   \n",
       "\n",
       "   inv_scot_n short_abstract lead_nut_code  \\\n",
       "0         0.0          False        [UKD3]   \n",
       "1         0.0          False        [UKH1]   \n",
       "2         0.0          False        [UKJ1]   \n",
       "3         1.0          False        [UKM8]   \n",
       "4         0.0          False        [UKH1]   \n",
       "\n",
       "                                  lead_nut_name  \\\n",
       "0                          [Greater Manchester]   \n",
       "1                                 [East Anglia]   \n",
       "2  [Berkshire, Buckinghamshire and Oxfordshire]   \n",
       "3                       [West Central Scotland]   \n",
       "4                                 [East Anglia]   \n",
       "\n",
       "                           all_nut_code  \\\n",
       "0                                [UKD3]   \n",
       "1  [UKH1, UKH2, UKK4, UKK1, UKJ1, UKJ1]   \n",
       "2                                [UKJ1]   \n",
       "3                                [UKM8]   \n",
       "4                                [UKH1]   \n",
       "\n",
       "                                        all_nut_name  \n",
       "0                               [Greater Manchester]  \n",
       "1  [East Anglia, Bedfordshire and Hertfordshire, ...  \n",
       "2       [Berkshire, Buckinghamshire and Oxfordshire]  \n",
       "3                            [West Central Scotland]  \n",
       "4                                      [East Anglia]  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtr_proj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discipline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each projects has a modelled discipline based on a predictive analysis that is fully reported in the source repo.\n",
    "\n",
    "#We assign each project to its top discipline\n",
    "\n",
    "disc_vars = [x for x in gtr_proj.columns if 'disc_' in x]\n",
    "\n",
    "gtr_proj['disc_top_discipline'] = gtr_proj[disc_vars].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create NUTS aggregations\n",
    "\n",
    "We are going to create the following:\n",
    "\n",
    "* Number of projects and level of funding led in the NUTS in various disciplines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discipline aggregates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the function above to create the geo by discipline aggregates\n",
    "disc = make_geo_var_stats(gtr_proj)\n",
    "\n",
    "#disc.to_csv(f'../../data/interim/gtr/{today_str}_nuts_discipline_activity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final processing and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/aux/gtr_stem_disciplines.txt','r') as infile:\n",
    "    \n",
    "    stem = infile.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of STEM projects per year and NUTS2 area\n",
    "disc_aggregate = disc[stem].sum(axis=1).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some final prep before saving\n",
    "#Rename columns\n",
    "disc_aggregate.rename(columns={'lead_nut_code':'nuts_id',0:'total_gtr_projects_stem'},inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_aggregate.drop('lead_nut_name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year nuts_id  nuts_year_spec  total_gtr_projects_stem\n",
      "0  2006    UKH2            2018                       45\n",
      "1  2007    UKH2            2018                       71\n",
      "2  2008    UKH2            2018                      106\n",
      "3  2009    UKH2            2018                       39\n",
      "4  2010    UKH2            2018                       53\n"
     ]
    }
   ],
   "source": [
    "make_indicator(disc_aggregate,'gtr',\n",
    "              {'total_gtr_projects_stem':'total_gtr_projects_stem'},'year',nuts_var='nuts_id',decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_nuts2_uk(pd.read_csv('../../data/processed/gtr/total_gtr_projects_stem.csv')\n",
    "             ).to_csv('../../data/processed/gtr/total_gtr_projects_stem.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluded indicators\n",
    "\n",
    "**These are not included in the final inventory so we have excluded them from the analysis (for now)**\n",
    "\n",
    "* Number of participations in research\n",
    "* Number of local collaboration in research (how many projects contain the same NUT more than once?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Volume of participation of research**\n",
    "\n",
    "We also want to capture the level of participation from organisations in research even when they are not leading projects (ie sites of universities).\n",
    "\n",
    "We will simply count instances when an organisation appears in a project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_process(nuts_freqs,lookup,name):\n",
    "    '''\n",
    "    \n",
    "    This is to avoid repetition when doing the final processing of nuts frequency series\n",
    "    \n",
    "    Args:\n",
    "        nut_freqs (series) a nuts freq where the index are nuts codes\n",
    "    \n",
    "    '''\n",
    "    #Reset the index\n",
    "    expand = nuts_freqs.reset_index(drop=False)\n",
    "    \n",
    "    #Add names using the lookup\n",
    "    expand['nuts_name'] = expand['index'].map(lookup)\n",
    "    \n",
    "    #Rename columns\n",
    "    expand.rename(columns={'index':'nuts_code',0:name},inplace=True)\n",
    "    \n",
    "    out = expand.set_index(['nuts_name','nuts_code'])\n",
    "    \n",
    "    return(out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many times does a NUTS 2 area participate at least once in a project\n",
    "\n",
    "research_participation = final_process(\n",
    "    flat_freq([list(set(x)) for x in gtr_proj['all_nut_code']]),nuts_code_to_name,'proj_participation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local collaborations**\n",
    "\n",
    "Finally, we want to calculate how many projects involve local collaborations.\n",
    "\n",
    "This one is a bit more complicated. We will do the following:\n",
    "\n",
    "* Extract pairs of combinations from each project NUTS list and concatenate them (this is an edge list)\n",
    "* Set them. If len ==1 then that is a local collaboration\n",
    "* Remove all len >1 & count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nice list comprehension: create a list of pairwise combinations from the collaborations, and keep those whose set length is 1 (both NUTS are the same)\n",
    "edge_list = [list(collab) for collab in [set(x) for x in flatten_list([list(combinations(x,2)) for x in gtr_proj['all_nut_code']])] if len(collab)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_collabs = final_process(flat_freq(edge_list),nuts_code_to_name,'local_collaborations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_activity = pd.concat([research_participation,local_collabs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_activity.to_csv(f'../../data/interim/gtr/{today_str}_research_act_collab.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick plot comparing project participation vs local collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_activity.sort_values('local_collaborations').apply(lambda x: x/x.sum()).plot.barh(figsize=(8,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "West London is massively overrepresented in the local collaborations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
