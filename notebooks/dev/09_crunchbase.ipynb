{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrunchBase indicators: number of organisations and investment.\n",
    "\n",
    "Here we produce indicators about level of Venture & Seed Funding in the UK using proprietary CrunchBase data licensed by Nesta. \n",
    "\n",
    "This involves:\n",
    "\n",
    "* Download the data from Nesta DAPS system\n",
    "* Merge organisations & funders to create org - funding matches\n",
    "* Geocode with NUTS2 and LEPS geographies\n",
    "* Create indicators\n",
    "  * This will be based on a function that subsets by year and distinguishes between seed funding and venture capital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import csv\n",
    "from data_getters.labs.core import download_file\n",
    "from ast import literal_eval\n",
    "from data_getters.core import get_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirs\n",
    "\n",
    "if 'crunchbase' not in os.listdir('../../data/raw'):\n",
    "    os.makedirs('../../data/raw/crunchbase')\n",
    "\n",
    "if 'crunchbase' not in os.listdir('../../data/processed/'):\n",
    "    os.makedirs('../../data/processed/crunchbase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../utilities.py\n",
    "# Some utilities\n",
    "\n",
    "import random\n",
    "\n",
    "def make_data_dict(table,name,path,sample=5):\n",
    "    '''\n",
    "    A function to output the form for a data dictionary\n",
    "    \n",
    "    Args:\n",
    "        -table (df) is the df we want to create the data dictionary for\n",
    "        -name (str) of the df\n",
    "        -path (str) is the place where we want to save the file\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    types = [estimate_type(table[x],sample=sample) for x in table.columns]\n",
    "        \n",
    "    data_dict = pd.DataFrame()\n",
    "    data_dict['variable'] = table.columns\n",
    "        \n",
    "    data_dict['type'] = types\n",
    "    \n",
    "    data_dict['description'] = ['' for x in data_dict['variable']]\n",
    "        \n",
    "    out = os.path.join(path,f'{today_str}_{name}.csv')\n",
    "    \n",
    "    #print(data_dict.columns)\n",
    "    \n",
    "    data_dict.to_csv(out)\n",
    "    \n",
    "\n",
    "def estimate_type(variable,sample):\n",
    "    '''\n",
    "    Estimates the type of a column. \n",
    "\n",
    "    Args:\n",
    "        variable (iterable) with values\n",
    "        sample (n) is the number of values to test\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    selection = random.sample(list(variable),sample)\n",
    "    \n",
    "    types = pd.Series([type(x) for x in selection]).value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    return(types.index[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df,name,path,today=today_str):\n",
    "    '''\n",
    "    Utility to save processed data quicker\n",
    "    \n",
    "    Arguments:\n",
    "        df (df) is the dataframe we want to save\n",
    "        name (str) is the name of the file\n",
    "        path (str) is the path where we want to save the file\n",
    "        today (str) is the day when the data is saved\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df.to_csv(f'{path}/{today_str}_{name}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daps_data(table,connection,chunksize=1000):\n",
    "    '''\n",
    "    Utility function to get data from DAPS with less faff\n",
    "    \n",
    "    Args:\n",
    "        -table is the SQL table in DAPS that we are extracting\n",
    "        -connection is the database connection we are using\n",
    "        -Chunksize are the chunks to download\n",
    "    \n",
    "    Returns:\n",
    "        -A dataframe with the data we have collected\n",
    "    \n",
    "    '''\n",
    "    #Get chunks\n",
    "    chunks = pd.read_sql_table(table, connection, chunksize=chunksize)\n",
    "    \n",
    "    #Create df\n",
    "    df = pd.concat(chunks)\n",
    "    \n",
    "    #Return data\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conversion(x,tid):\n",
    "    '''\n",
    "    Function to convert funding rounds from CrunchBase into GBP\n",
    "    \n",
    "    Args:\n",
    "        transaction: a transaction from the CB funding rounds dataset\n",
    "        tid: transaction id (to track issues)\n",
    "    \n",
    "    Returns:\n",
    "        A conversion (if possible)\n",
    "    '''\n",
    "    \n",
    "    #If an amount is not in GBP convert to GBP, if not, keep it as is\n",
    "    \n",
    "    #The currency converter doesn't work with Lebanese pounds so we will skip that\n",
    "    if (x['raised_amount_currency_code']=='LBP')|(x['raised_amount_currency_code']==None):\n",
    "        return(np.nan)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        try:\n",
    "            out = x['raised_amount']*c.get_rate(\n",
    "                x['raised_amount_currency_code'],'GBP',x['announced_on']) if x['raised_amount_currency_code']!='GBP' else x['raised_amount']\n",
    "            return(out)\n",
    "\n",
    "        except: \n",
    "            print(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_investments(df,years,geography):\n",
    "    '''\n",
    "    This function aggregates level of funding over a geography and investment type for a selected period\n",
    "    \n",
    "    Arguments:\n",
    "        df: df with investment levels by geocoded organisaton, year and type\n",
    "        years: (list) year range to be considered\n",
    "        geography: (str) what geography name to use\n",
    "    \n",
    "    Returns a table where the rows are the geography and the columns are levels of funding by investment type\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Period to consider\n",
    "    period = np.arange(years[0],years[1])\n",
    "    \n",
    "    #Subset by the year\n",
    "    df_in_period = df.loc[[x.year in period for x in df['announced_on']]]\n",
    "    \n",
    "    #Pivot\n",
    "    out = pd.pivot_table(df_in_period,index=geography,columns='investment_type',values='raised_amount_gbp',aggfunc='sum').fillna(0)\n",
    "    \n",
    "    return(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CrunchBase data using DAPS\n",
    "\n",
    "my_config = '../../mysqldb_team.config'\n",
    "\n",
    "#Create connection with SQL\n",
    "con = get_engine(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organisations\n",
    "\n",
    "This is the list of organisations we want to wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "cb_orgs = get_daps_data('crunchbase_organizations',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_orgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every organisation has an id and a location id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funding rounds\n",
    "\n",
    "Funding rounds for organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_funding_rounds = get_daps_data('crunchbase_funding_rounds',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_funding_rounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each funding round has the company name and location id, the investment type and the year. This means that we don't need the organisation data for the funding measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse geocoded place ids\n",
    "\n",
    "We have reverse geocoded place ids with their NUTS and LEPS code in notebook `0_rev_geocoder`. \n",
    "\n",
    "We load that information here and use it to generate indicators of activity by NUTS and LEPS area in the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv('../../data/processed/crunchbase/2020_01_28_rev_geocoded_places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Number of technology companies indicator\n",
    "\n",
    "This is the number of active companies in a NUTS or LEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_orgs_geo = pd.merge(cb_orgs,places,left_on='location_id',right_on='location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_orgs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on active companies\n",
    "\n",
    "uk_comps = cb_orgs_geo.loc[(cb_orgs_geo['primary_role']=='company')&(cb_orgs_geo['status']=='operating')&(cb_orgs_geo['country']=='United Kingdom')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_comps['nuts218nm'].value_counts().head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_comps['lep17nm'].value_counts().head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create activity files\n",
    "nuts_orgs,leps_orgs = [uk_comps.groupby(var).size() for var in [['nuts218nm','nuts218cd'],['lep17nm','lep17cd']]]\n",
    "\n",
    "#Name the series\n",
    "nuts_orgs.name='company_n'\n",
    "leps_orgs.name='company_n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Level of VC and seed funding indicator\n",
    "\n",
    "Here we merge the geocoded df with the funding one and then create a function that aggregates funding by location & category for a threshold year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_geo = pd.merge(cb_funding_rounds,places,left_on='location_id',right_on='location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will need a python currency converter.\n",
    "inv_geo['raised_amount_currency_code'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_geo.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion strategy\n",
    "\n",
    "We will use the announcement date and the currency information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forex_python.converter import CurrencyRates\n",
    "c = CurrencyRates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If an amount is not in GBP convert to GBP, if not, keep it as is\n",
    "\n",
    "inv_geo['raised_amount_gbp'] = [make_conversion(x,rid) for rid,x in inv_geo.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the indicators_w_threshold function to calculate levels of investment by NUTS and LEPS area\n",
    "inv_nuts_2,inv_leps = [aggregate_investments(inv_geo,[2010,2019],var) for var in ['nuts218nm','lep17nm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_nuts_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_nuts_2.sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_nuts_2.sum(axis=1).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Org_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../../data/processed/crunchbase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file,name in zip([nuts_orgs,inv_nuts_2,leps_orgs,inv_leps],['nuts_2_orgs','nuts_2_investment','leps_orgs','leps_investment']):\n",
    "    save_data(file,name,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
