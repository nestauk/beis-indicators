{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrunchBase\n",
    "\n",
    "Here we produce indicators about level of Venture & Seed Funding in the UK using proprietary CrunchBase data licensed by Nesta. \n",
    "\n",
    "This involves:\n",
    "\n",
    "* Download the data from Nesta DAPS system\n",
    "* Merge organisations & funders to create org - funding matches\n",
    "* Geocode with NUTS2 and LEPS geographies\n",
    "* Create indicators\n",
    "  * This will be based on a function that subsets by year and distinguishes between seed funding and venture capital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import csv\n",
    "from data_getters.labs.core import download_file\n",
    "from ast import literal_eval\n",
    "from data_getters.core import get_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirs\n",
    "\n",
    "if 'crunchbase' not in os.listdir('../../data/raw'):\n",
    "    os.makedirs('../../data/raw/crunchbase')\n",
    "\n",
    "if 'crunchbase' not in os.listdir('../../data/processed/'):\n",
    "    os.makedirs('../../data/processed/crunchbase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../utilities.py\n",
    "# Some utilities\n",
    "\n",
    "import random\n",
    "\n",
    "def make_data_dict(table,name,path,sample=5):\n",
    "    '''\n",
    "    A function to output the form for a data dictionary\n",
    "    \n",
    "    Args:\n",
    "        -table (df) is the df we want to create the data dictionary for\n",
    "        -name (str) of the df\n",
    "        -path (str) is the place where we want to save the file\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    types = [estimate_type(table[x],sample=sample) for x in table.columns]\n",
    "        \n",
    "    data_dict = pd.DataFrame()\n",
    "    data_dict['variable'] = table.columns\n",
    "        \n",
    "    data_dict['type'] = types\n",
    "    \n",
    "    data_dict['description'] = ['' for x in data_dict['variable']]\n",
    "        \n",
    "    out = os.path.join(path,f'{today_str}_{name}.csv')\n",
    "    \n",
    "    #print(data_dict.columns)\n",
    "    \n",
    "    data_dict.to_csv(out)\n",
    "    \n",
    "\n",
    "def estimate_type(variable,sample):\n",
    "    '''\n",
    "    Estimates the type of a column. \n",
    "\n",
    "    Args:\n",
    "        variable (iterable) with values\n",
    "        sample (n) is the number of values to test\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    selection = random.sample(list(variable),sample)\n",
    "    \n",
    "    types = pd.Series([type(x) for x in selection]).value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    return(types.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daps_data(table,connection,chunksize=1000):\n",
    "    '''\n",
    "    Utility function to get data from DAPS with less faff\n",
    "    \n",
    "    Args:\n",
    "        -table is the SQL table in DAPS that we are extracting\n",
    "        -connection is the database connection we are using\n",
    "        -Chunksize are the chunks to download\n",
    "    \n",
    "    Returns:\n",
    "        -A dataframe with the data we have collected\n",
    "    \n",
    "    '''\n",
    "    #Get chunks\n",
    "    chunks = pd.read_sql_table(table, connection, chunksize=chunksize)\n",
    "    \n",
    "    #Create df\n",
    "    df = pd.concat(chunks)\n",
    "    \n",
    "    #Return data\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CrunchBase data using DAPS\n",
    "\n",
    "my_config = '../../mysqldb_team.config'\n",
    "\n",
    "#Create connection with SQL\n",
    "con = get_engine(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organisations\n",
    "\n",
    "This is the list of organisations we want to wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "cb_orgs = get_daps_data('crunchbase_organizations',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_orgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every organisation has an id and a location id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funding rounds\n",
    "\n",
    "Funding rounds for organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_funding_rounds = get_daps_data('crunchbase_funding_rounds',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_funding_rounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each funding round has the company name and location id, the investment type and the year. This means that we don't need the organisation data for the funding measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse geocoded place ids\n",
    "\n",
    "We have reverse geocoded place ids with their NUTS and LEPS code in notebook `0_rev_geocoder`. \n",
    "\n",
    "We load that information here and use it to generate indicators of activity by NUTS and LEPS area in the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv('../../data/processed/crunchbase/2020_01_28_rev_geocoded_places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Number of technology companies indicator\n",
    "\n",
    "This is the number of active companies in a NUTS or LEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_orgs_geo = pd.merge(cb_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographies\n",
    "\n",
    "Locations for organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_df = get_daps_data('geographic_data',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every city had an id that can be matched with the CB data and a lat,lon that can be used for geoocoding"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
