{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHE places\n",
    "\n",
    "We collect data about median salaries in a NUTS2 area. This is an indicator in its own right, and we will also use it to calculate the House Affordability index.\n",
    "\n",
    "Our strategy will be to collect the data from [Nomis](https://www.nomisweb.co.uk/query/construct/apilinks.asp?menuopt=201) for LEPS.\n",
    "\n",
    "Unfortunately the data is not available at the NUTS2 so we will have to use an alternative source\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(name,dirs = ['raw','processed']):\n",
    "    '''\n",
    "    Utility that creates directories to save the data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for d in dirs:\n",
    "        if name not in os.listdir(f'../../data/{d}'):\n",
    "            os.mkdir(f'../../data/{d}/{name}')\n",
    "            \n",
    "def flat_freq(a_list):\n",
    "    '''\n",
    "    Return value counts for categories in a nested list\n",
    "    \n",
    "    '''\n",
    "    return(pd.Series([x for el in a_list for x in el]).value_counts())\n",
    "\n",
    "        \n",
    "\n",
    "def flatten_list(a_list):\n",
    "    \n",
    "    return([x for el in a_list for x in el])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df,name,path,today=today_str):\n",
    "    '''\n",
    "    Utility to save processed data quicker\n",
    "    \n",
    "    Arguments:\n",
    "        df (df) is the dataframe we want to save\n",
    "        name (str) is the name of the file\n",
    "        path (str) is the path where we want to save the file\n",
    "        today (str) is the day when the data is saved\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df.to_csv(f'{path}/{today_str}_{name}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_ashe_place(api_link,var_name):\n",
    "    '''\n",
    "    This function collects and processes ashe place data\n",
    "    \n",
    "    Arguments:\n",
    "        api_link (str) is the endpoint we get the data from\n",
    "        var_name (str) is the name for the observed value variable\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Get the data\n",
    "    nomis_table = pd.read_csv(api_link)\n",
    "    \n",
    "    #tidy variable names\n",
    "    nomis_table.columns = [x.lower() for x in nomis_table.columns]\n",
    "    \n",
    "    #Some subseting of rows (ie we only keep the values)\n",
    "    nomis_values = nomis_table.loc[nomis_table['measures_name']=='Value']\n",
    "    \n",
    "    #Some subsetting of columns\n",
    "    nomis_filtered = nomis_values[['date_name','geography_name','geography_code','obs_value']]\n",
    "    \n",
    "    #Observed value\n",
    "    nomis_filtered.rename(columns={'obs_value':'var_name'})\n",
    "    \n",
    "    return(nomis_filtered)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ashe_dump_data(path,file,occupation_list):\n",
    "    '''\n",
    "    This function collects and parses data from an ASHE occupation salary dump\n",
    "    \n",
    "    Arguments:\n",
    "        path (str) is the path where we have stored the excel files\n",
    "        file (str) is the name of the file\n",
    "        occupation_list (list) is the list of occupations that we will focus on    \n",
    "    \n",
    "    '''\n",
    "    #Extract the year from the file name\n",
    "    year = file.split(' ')[-1][:-4]\n",
    "    \n",
    "    print(year)\n",
    "    \n",
    "    \n",
    "    #Read the file. We are focusin on Full-Time to keep the indicator comparable with the LEPS. \n",
    "    #We are also subsetting to remove some information at the top / bottom / sides\n",
    "    \n",
    "    table = pd.read_excel(path+'/'+file,\n",
    "                    sheet_name='Full-Time',skiprows=4,na_values='x').iloc[:-5,:4]\n",
    "    \n",
    "    #Extract NUTS and occupations from the 'Descriptionc' field\n",
    "    \n",
    "    #We will use the fact that occupations are all Uppercase\n",
    "    \n",
    "    place_names = []\n",
    "    occ_names = []\n",
    "    \n",
    "    #We go through every description and if a word is all uppercase we put it in an occupation container,\n",
    "    #otherwise in a place container\n",
    "    \n",
    "    for category in table['Descriptionc']:\n",
    "        \n",
    "        split = category.split(' ')\n",
    "        \n",
    "        place =[]\n",
    "        occ = []\n",
    "        \n",
    "        for word in split:\n",
    "            if word.isupper()==False:\n",
    "                place.append(word)\n",
    "                \n",
    "            else:\n",
    "                occ.append(word)\n",
    "                \n",
    "        place_names.append(' '.join(place))\n",
    "        occ_names.append(' '.join(occ))\n",
    "        \n",
    "    #Assign the words we identified as places to NUTS2 removing a trailing comma\n",
    "    table['nuts_2'] = [x[:-1] for x in place_names]\n",
    "    \n",
    "    #Assign occupations\n",
    "    table['occupation'] = occ_names\n",
    "    \n",
    "    #Assign years\n",
    "    table['year']=year\n",
    "    \n",
    "    #Focus on occupations of interest\n",
    "    table_filter = table.loc[[x in occupation_list for x in table['occupation']]]\n",
    "    \n",
    "    #Clean the occupation name\n",
    "    table_filter['occupation'] =[x.lower() for x in table_filter['occupation']]\n",
    "    \n",
    "    #Rename the median variable\n",
    "    table_filter.rename(columns={'Median':'gross_annual_salary_median'},inplace=True)\n",
    "    \n",
    "    return(table_filter[['year','nuts_2','occupation','gross_annual_salary_median']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_indicator(table,target_path,var_lookup,year_var,nuts_var='nuts_code',nuts_spec=2018,decimals=3):\n",
    "    '''\n",
    "    We use this function to create and save indicators using our standardised format.\n",
    "    \n",
    "    Args:\n",
    "        table (df) is a df with relevant information\n",
    "        target_path (str) is the location of the directory where we want to save the data (includes interim and processed)\n",
    "        var_lookup (dict) is a lookup to rename the variable into our standardised name\n",
    "        year (str) is the name of the year variable\n",
    "        nuts_var (str) is the name of the NUTS code variable. We assume it is nuts_code\n",
    "        nuts_spec (y) is the value of the NUTS specification. We assume we are working with 2018 NUTS\n",
    "    \n",
    "    '''\n",
    "    #Copy\n",
    "    t = table.reset_index(drop=False)\n",
    "    \n",
    "    #Reset index (we assume that the index is the nuts code, var name and year - this might need to be changed)\n",
    "    \n",
    "    \n",
    "    #Process the interim data into an indicator\n",
    "    \n",
    "    #This is the variable name and code\n",
    "    var_name = list(var_lookup.keys())[0]\n",
    "    \n",
    "    var_code = list(var_lookup.values())[0]\n",
    "    \n",
    "    #Focus on those\n",
    "    t = t[[year_var,nuts_var,var_name]]\n",
    "    \n",
    "    #Add the nuts specification\n",
    "    t['nuts_year_spec'] = nuts_spec\n",
    "    \n",
    "    #Rename variables\n",
    "    t.rename(columns={var_name:var_code,year_var:'year',nuts_var:'nuts_id'},inplace=True)\n",
    "\n",
    "    #Round variables\n",
    "    if decimals>0:\n",
    "        t[var_code] = [np.round(x,decimals) for x in t[var_code]]\n",
    "    #If we have zero decimals, cast as int\n",
    "    #else:\n",
    "    #    t[var_code] = t[var_code].astype(int)\n",
    "    \n",
    "    #Reorder variables\n",
    "    t = t[['year','nuts_id','nuts_year_spec',var_code]]\n",
    "    \n",
    "    print(t.head())\n",
    "    \n",
    "    #Save in the processed folder\n",
    "    t.to_csv(f'../../data/processed/{target_path}/{var_code}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirs\n",
    "\n",
    "if 'ashe_place' not in os.listdir('../../data/raw'):\n",
    "    os.makedirs('../../data/raw/ashe_place')\n",
    "\n",
    "if 'ashe_place' not in os.listdir('../../data/interim/'):\n",
    "    os.makedirs('../../data/interim/ashe_place')\n",
    "    \n",
    "if 'ashe_place' not in os.listdir('../../data/processed/'):\n",
    "    os.makedirs('../../data/processed/ashe_place')\n",
    "\n",
    "#Path to save data:\n",
    "\n",
    "int_path ='../../data/interim/ashe_place'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data\n",
    "\n",
    "We collect the data from NOMIS.\n",
    "\n",
    "Note that we are collecting **annual gross salary** for full-time workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEPS\n",
    "\n",
    "The LEP case will be easy as the information is already available at the lep level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_lep_link = 'https://www.nomisweb.co.uk/api/v01/dataset/NM_30_1.data.csv?geography=1925185537,1925185575,1925185538...1925185543,1925185572,1925185544,1925185570,1925185545,1925185577,1925185553,1925185547...1925185549,1925185571,1925185569,1925185551,1925185552,1925185554,1925185558,1925185555...1925185557,1925185559,1925185560,1925185550,1925185576,1925185562,1925185573,1925185563...1925185568&date=latestMINUS4-latest&sex=8&item=2&pay=7&measures=20100,20701'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ashe_lep = get_process_ashe_place(api_lep_link,'gross_annual_salary_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_name</th>\n",
       "      <th>geography_name</th>\n",
       "      <th>geography_code</th>\n",
       "      <th>obs_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Black Country</td>\n",
       "      <td>E37000001</td>\n",
       "      <td>24174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>Buckinghamshire Thames Valley</td>\n",
       "      <td>E37000002</td>\n",
       "      <td>32343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>Cheshire and Warrington</td>\n",
       "      <td>E37000003</td>\n",
       "      <td>28191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>Coast to Capital</td>\n",
       "      <td>E37000004</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>Cornwall and Isles of Scilly</td>\n",
       "      <td>E37000005</td>\n",
       "      <td>23354.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_name                 geography_name geography_code  obs_value\n",
       "0       2015                  Black Country      E37000001    24174.0\n",
       "2       2015  Buckinghamshire Thames Valley      E37000002    32343.0\n",
       "4       2015        Cheshire and Warrington      E37000003    28191.0\n",
       "6       2015               Coast to Capital      E37000004    30000.0\n",
       "8       2015   Cornwall and Isles of Scilly      E37000005    23354.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashe_lep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS2\n",
    "\n",
    "ASHE data are not available at the NUTS2 level and it is not trivial to convert LAD data into NUTS as we have done in other places (eg House Affordability) because the information is only available as median salaries. We could have used number of jobs & average salaries to calculate wage bills and recalculate salaries at the NUTS2 level but this would mean reporting averages rather than medians. \n",
    "\n",
    "For all these reasons, we end using a ASHE data dump at the ONS level available [here](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/adhocs/009571annualsurveyofhoursandearningsasheestimatesofannualandhourlyearningsforindustryandoccupationbynuts2andnuts3uk2011to2017)\n",
    "\n",
    "Note that there are some concerns about the reliability of these indicators given small sample sizes etc. so any indicators built using this data should be treated with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and extract the ASHE data\n",
    "data_link = 'https://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/adhocs/009571annualsurveyofhoursandearningsasheestimatesofannualandhourlyearningsforindustryandoccupationbynuts2andnuts3uk2011to2017/k42forpublishing.zip'\n",
    "\n",
    "ashe_req = requests.get(data_link)\n",
    "ashe_zip = ZipFile(BytesIO(ashe_req.content))\n",
    "ashe_zip.extractall(path='../../data/raw/ashe_place/download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted data are a bunch of excel files with median data by occupation and industry between 2011 and 2017.\n",
    "\n",
    "We will focus on Science, Engineering and technology occupations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ad hoc K42a_11 Ad Hoc K42a7a   Annual pay - Gross 2011.xls',\n",
       " 'Ad hoc K42a_12_13 Ad Hoc K42a7a   Annual pay - Gross 2012.xls',\n",
       " 'Ad hoc K42a_12_13 Ad Hoc K42a7a   Annual pay - Gross 2013.xls',\n",
       " 'Ad hoc K42a_14_16 Ad Hoc K42a7a   Annual pay - Gross 2014.xls',\n",
       " 'Ad hoc K42a_14_16 Ad Hoc K42a7a   Annual pay - Gross 2015.xls',\n",
       " 'Ad hoc K42a_14_16 Ad Hoc K42a7a   Annual pay - Gross 2016.xls',\n",
       " 'Ad hoc K42a_17 Ad Hoc K42a7a   Annual pay - Gross 2017.xls']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dir = os.listdir('../../data/raw/ashe_place/download/K42a - NUTS2 by occupation')\n",
    "\n",
    "#Files we want to consider\n",
    "my_files = [x for x in my_dir if ('Annual pay' in x) & (' CV' not in x)]\n",
    "\n",
    "my_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/raw/ashe_place/download/K42a - NUTS2 by occupation'\n",
    "occ_list = ['SCIENCE, RESEARCH, ENGINEERING AND TECHNOLOGY PROFESSIONALS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0225c9266973>:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_filter['occupation'] =[x.lower() for x in table_filter['occupation']]\n",
      "/Users/jmateosgarcia/anaconda3/envs/beis_dash/lib/python3.8/site-packages/pandas/core/frame.py:4238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "sci_median_salaries = pd.concat([parse_ashe_dump_data(path,file,occ_list) for file in my_files]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>nuts_2</th>\n",
       "      <th>occupation</th>\n",
       "      <th>gross_annual_salary_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>Tees Valley and Durham</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>32961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>Northumberland and Tyne and Wear</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>35185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>Cumbria</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>40351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>Cheshire</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>37419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Greater Manchester</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>36333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2017</td>\n",
       "      <td>Highlands and Islands</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>36710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2017</td>\n",
       "      <td>Eastern Scotland</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>38952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2017</td>\n",
       "      <td>West Central Scotland</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>37511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2017</td>\n",
       "      <td>Southern Scotland</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>40704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2017</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>36792.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                            nuts_2  \\\n",
       "0    2011            Tees Valley and Durham   \n",
       "1    2011  Northumberland and Tyne and Wear   \n",
       "2    2011                           Cumbria   \n",
       "3    2011                          Cheshire   \n",
       "4    2011                Greater Manchester   \n",
       "..    ...                               ...   \n",
       "267  2017             Highlands and Islands   \n",
       "268  2017                  Eastern Scotland   \n",
       "269  2017             West Central Scotland   \n",
       "270  2017                 Southern Scotland   \n",
       "271  2017                  Northern Ireland   \n",
       "\n",
       "                                            occupation  \\\n",
       "0    science, research, engineering and technology ...   \n",
       "1    science, research, engineering and technology ...   \n",
       "2    science, research, engineering and technology ...   \n",
       "3    science, research, engineering and technology ...   \n",
       "4    science, research, engineering and technology ...   \n",
       "..                                                 ...   \n",
       "267  science, research, engineering and technology ...   \n",
       "268  science, research, engineering and technology ...   \n",
       "269  science, research, engineering and technology ...   \n",
       "270  science, research, engineering and technology ...   \n",
       "271  science, research, engineering and technology ...   \n",
       "\n",
       "     gross_annual_salary_median  \n",
       "0                       32961.0  \n",
       "1                       35185.0  \n",
       "2                       40351.0  \n",
       "3                       37419.0  \n",
       "4                       36333.0  \n",
       "..                          ...  \n",
       "267                     36710.0  \n",
       "268                     38952.0  \n",
       "269                     37511.0  \n",
       "270                     40704.0  \n",
       "271                     36792.0  \n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_median_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We fix a typo in one of the geographies (they switched the order of Bristol and Bath)\n",
    "sci_median_salaries['nuts_2'] = ['Gloucestershire, Wiltshire and Bath/Bristol area' \n",
    "                                 if x=='Gloucestershire, Wiltshire and Bristol/Bath area' else x for x in sci_median_salaries['nuts_2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final processing\n",
    "\n",
    "Add NUTS2 codes to the table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_codes_url = 'https://opendata.arcgis.com/datasets/ded3b436114440e5a1561c1e53400803_0.geojson'\n",
    "\n",
    "nuts_codes_names = requests.get(nuts_codes_url).json()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add NUTS2 codes\n",
    "nuts_names_to_codes = {x['properties']['NUTS218NM']:x['properties']['NUTS218CD'] for x in nuts_codes_names}\n",
    "\n",
    "#Label the table with 2018 NUTS codes. \n",
    "sci_median_salaries['nuts_2_codes'] = [nuts_names_to_codes[x] if x in nuts_names_to_codes.keys() else np.nan for x in sci_median_salaries['nuts_2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gloucestershire, Wiltshire and North Somerset',\n",
       " 'Inner London',\n",
       " 'Outer London',\n",
       " 'South Western Scotland',\n",
       " 'West Wales'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sci_median_salaries.loc[sci_median_salaries['nuts_2_codes'].isna()]['nuts_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small number of mismatched areas due to changes in NUTS, plus aggregate non-NUTS london codes. We need to decide what to do about these.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(ashe_lep,'ashe_lep_all_occupations',int_path)\n",
    "\n",
    "save_data(sci_median_salaries,'ashe_nuts_2_sci_tech',int_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ASHE place indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>nuts_2</th>\n",
       "      <th>occupation</th>\n",
       "      <th>gross_annual_salary_median</th>\n",
       "      <th>nuts_2_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2011</td>\n",
       "      <td>Highlands and Islands</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKM6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2012</td>\n",
       "      <td>Devon</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKK4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2014</td>\n",
       "      <td>Shropshire and Staffordshire</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2014</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKN0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2015</td>\n",
       "      <td>Essex</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKH3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2015</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKM5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2016</td>\n",
       "      <td>Northumberland and Tyne and Wear</td>\n",
       "      <td>science, research, engineering and technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKC2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                            nuts_2  \\\n",
       "35   2011             Highlands and Islands   \n",
       "66   2012                             Devon   \n",
       "126  2014      Shropshire and Staffordshire   \n",
       "150  2014                  Northern Ireland   \n",
       "170  2015                             Essex   \n",
       "188  2015            North Eastern Scotland   \n",
       "192  2016  Northumberland and Tyne and Wear   \n",
       "\n",
       "                                            occupation  \\\n",
       "35   science, research, engineering and technology ...   \n",
       "66   science, research, engineering and technology ...   \n",
       "126  science, research, engineering and technology ...   \n",
       "150  science, research, engineering and technology ...   \n",
       "170  science, research, engineering and technology ...   \n",
       "188  science, research, engineering and technology ...   \n",
       "192  science, research, engineering and technology ...   \n",
       "\n",
       "     gross_annual_salary_median nuts_2_codes  \n",
       "35                          NaN         UKM6  \n",
       "66                          NaN         UKK4  \n",
       "126                         NaN         UKG2  \n",
       "150                         NaN         UKN0  \n",
       "170                         NaN         UKH3  \n",
       "188                         NaN         UKM5  \n",
       "192                         NaN         UKC2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_median_salaries.loc[sci_median_salaries['gross_annual_salary_median'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year nuts_id  nuts_year_spec  gbp_gross_median_salary_s_t\n",
      "0  2011    UKC1            2018                      32961.0\n",
      "1  2011    UKC2            2018                      35185.0\n",
      "2  2011    UKD1            2018                      40351.0\n",
      "3  2011    UKD6            2018                      37419.0\n",
      "4  2011    UKD3            2018                      36333.0\n"
     ]
    }
   ],
   "source": [
    "make_indicator(sci_median_salaries,'ashe_place',{'gross_annual_salary_median':'gbp_gross_median_salary_s_t'},\n",
    "               nuts_var='nuts_2_codes',decimals=0,year_var='year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
